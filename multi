from datetime import datetime
from matplotlib import pyplot
import numpy as np

import sklearn
from sklearn import neighbors, datasets, preprocessing
from keras.models import Sequential
from keras.layers import Dense, LSTM
import pandas as pd
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.metrics import mean_squared_error

df = pd.read_csv(('https://archive.ics.uci.edu/ml/machine-learning-databases/'
                  '00381/PRSA_data_2010.1.1-2014.12.31.csv'),   #importa o dataset
                 index_col=0,   #primeira coluna se torna index
                 parse_dates=[['year', 'month', 'day', 'hour']],   #selecionou as colunas que contém a data
                 date_parser=lambda x: datetime.strptime(x, '%Y %m %d %H')  # colocou a data no formato do datetime
                ).drop('No', axis=1)  #dropou a coluna 'no'
df.head()
df.columns = ['pollution', 'dew', 'temp', 'press',
              'wnd_dir', 'wnd_spd', 'snow', 'rain']   #Renomeou as colunas
df.index.name = 'date'  # renomeou o index
df.head()

df.pollution.count()
df.shape
df['pollution'].fillna(0, inplace=True)
df.pollution.count()
df.head()
#gráficos
_ = df.plot(subplots=True, figsize=(15,10))
#options
n_lags = 3
n_train_obs = 365 * 24
epochs = 50
layers = (50, 1)
n_features = df.shape[1]

#tratando variaveis categoricas
df.dtypes
cat_cols = df.select_dtypes(include=[object]).columns
cat_cols
encoders = {}
for cat_col in cat_cols:
    encoders[cat_col] = LabelEncoder() #tranforma as variáveis categoricas em 1,2,3,4...
    df[cat_col] = encoders[cat_col].fit_transform(df[cat_col].values)
encoders[cat_col].classes_
df[cat_col].values

#Criando um timelag, que é uma translação de tempo. o 0 representa o tempo atual e 1,2,3 os tempos passados em intervalor de 1 hora
pd.options.display.max_columns = 130
dfs = []
for i in range(n_lags, -1, -1):  #3,2,1,0
    tmp = df.copy()\
            .shift(i)\
            .rename(columns=lambda x: '{}-{}'.format(x, i) if i > 0 else x)
    dfs.append(tmp)   # o shift pega as mudanças de valor
df = pd.concat(dfs, axis=1).dropna()
df.head()

#Scaler - transforma todas os valores em uma mesma escala de 0 a 1
scaler = MinMaxScaler(feature_range=(0, 1))
df = pd.DataFrame(scaler.fit_transform(df),
                  index=df.index, columns=df.columns)
df.head()

#Train test
values = df.values
values.shape
train = values[:n_train_obs, :]
train.shape
test = values[n_train_obs:, :]
test.shape

n_obs = n_lags * n_features
train_X, train_y = train[:, :n_obs], train[:, -n_features]
test_X, test_y = test[:, :n_obs], test[:, -n_features]
train_X.shape
train_y.shape
test_X.shape
test_y.shape

train_X = train_X.reshape((train_X.shape[0], n_lags, n_features))
test_X = test_X.reshape((test_X.shape[0], n_lags, n_features))
train_X.shape
test_X.shape

#model - Long short term memory
model = Sequential()
model.add(LSTM(layers[0], input_shape=(train_X.shape[1], train_X.shape[2])))
model.add(Dense(1))
model.compile(loss='mae', optimizer='adam')

history = model.fit(train_X, train_y, epochs=epochs, batch_size=72,
                    validation_data=(test_X, test_y), verbose=1, shuffle=False)

# See convergence
pyplot.plot(history.history['loss'], label='train')
pyplot.plot(history.history['val_loss'], label='test')
pyplot.legend()
pyplot.show()

yhat = model.predict(test_X)    # predict the outputs (y) of the test data
yhat.shape
test_X = test_X.reshape((test_X.shape[0], n_lags*n_features))  #reshape back from 3*8 to 24
test_X.shape

inv_yhat = np.concatenate((yhat, df.drop(df.columns[0], axis=1).values[n_train_obs:,:]), axis=1)
#concatenate yhat with df, keeping the number of samples of yhat and adding df features
#What happens here is that we made 3 lags, but there is an original timelag that is not considered on the model
inv_yhat.shape
df.shape
n_train_obs
inv_yhat = scaler.inverse_transform(inv_yhat) #undo scale
inv_yhat.shape
inv_yhat = inv_yhat[:,0]
inv_yhat.shape
inv_yhat

test_y = test_y.reshape((len(test_y), 1))
test_y.shape
inv_y = np.concatenate((test_y, df.drop(df.columns[0], axis=1).values[n_train_obs:,:]), axis=1)
inv_y.shape
inv_y = scaler.inverse_transform(inv_y)
inv_y = inv_y[:,0]
inv_y.shape
inv_y

rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))
print('Test RMSE: %.3f' % rmse)


import this
